<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>概率论与数理统计 | Matrix</title><meta name="author" content="CarlyleLiu"><meta name="copyright" content="CarlyleLiu"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="原图">
<meta property="og:type" content="article">
<meta property="og:title" content="概率论与数理统计">
<meta property="og:url" content="https://carlyleliu.github.io/Science/ProbabilityTheoryandMathematicalStatistics/index.html">
<meta property="og:site_name" content="Matrix">
<meta property="og:description" content="原图">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://unsplash.it/1600/900?random&7417">
<meta property="article:published_time" content="2022-03-13T11:53:27.000Z">
<meta property="article:modified_time" content="2025-09-27T04:36:15.374Z">
<meta property="article:author" content="CarlyleLiu">
<meta property="article:tag" content="Math">
<meta property="article:tag" content="Linear Algebra">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://unsplash.it/1600/900?random&7417"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://carlyleliu.github.io/Science/ProbabilityTheoryandMathematicalStatistics/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":false,"highlightHeightLimit":300},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '概率论与数理统计',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2025-09-27 12:36:15'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<link rel="stylesheet" href="https://unpkg.zhimg.com/hexo-butterfly-footer-beautify@1.0.0/lib/runtime.min.css" media="print" onload="this.media='all'"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.2.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="alternate" href="/atom.xml" title="Matrix" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">194</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">42</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">28</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://unsplash.it/1600/900?random&amp;7417')"><nav id="nav"><span id="blog-info"><a href="/" title="Matrix"><span class="site-name">Matrix</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">概率论与数理统计</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-03-13T11:53:27.000Z" title="发表于 2022-03-13 19:53:27">2022-03-13</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-09-27T04:36:15.374Z" title="更新于 2025-09-27 12:36:15">2025-09-27</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Science-Thought/">Science Thought</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Science-Thought/Math/">Math</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="概率论与数理统计"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p><img src="https://lsky.carlyleliu.vip/carlyleliu/ImageHosting/TechnologyBlog/Science/Math/ProbabilityTheoryandMathematicalStatistics.png" alt=""><br><a target="_blank" rel="noopener" href="https://www.processon.com/embed/621e1d55637689212299da45">原图</a></p>
<span id="more"></span>
<h1 id="概率论基本概念"><a href="#概率论基本概念" class="headerlink" title="概率论基本概念"></a>概率论基本概念</h1><h2 id="概率的派别"><a href="#概率的派别" class="headerlink" title="概率的派别"></a>概率的派别</h2><p>对于概率的定义有几个主流的派别：</p>
<ul>
<li><p>频率派：<br>  频率派认为如果频率存在稳定性，即当$n\to\infty$时下面极限存在（下面这个写法只是示意，后面介绍大数定律的时候会给出严格的定义），就得到了概率（用 Probability 的首字母 P 来表示）：</p>
<script type="math/tex; mode=display">
  P（正面）=\lim_{n\to\infty}P_{n}（正面）</script></li>
<li><p>古典派：<br>  如果因为无知，使得我们没有办法判断哪一个结果会比另外一个结果更容易出现，那么应该给予它们相同的概率，此称为不充分理由原则（Insufficient Reason Principle）。以不充分理由原则为基础，经由拉普拉斯：之手，确立了古典概率的定义，即：<br>  未知的概率都为等概率</p>
</li>
<li><p>主观派：<br>  最后介绍下主观派，主观派认为概率是信念强度（degree of belief）。比如说，我个人相信 20 年后人类从网络时代进入人工智能时代的概率为 70%.</p>
</li>
</ul>
<p>三个流派大概有以下的区别：</p>
<script type="math/tex; mode=display">
\begin{array}{c|c}
    \hline
    \quad\quad&\quad\color{orange}{频率派}\quad&\quad\color{blue}{古典派}\quad&\quad\color{ForestGreen}{主观派}\quad\\
    \hline \\
    \quad 理论基础 \quad&\quad 过往事实的归纳总结、quad&\quad 不充分理由原则、quad&\quad 知识和直觉、quad\\
    \quad 概率定义 \quad&\quad 频率稳定性、quad&\quad 等概率、quad&\quad 信念强度、quad\\
    \\\hline
\end{array}</script><h2 id="概率公理化"><a href="#概率公理化" class="headerlink" title="概率公理化"></a>概率公理化</h2><p>已知某样本空间$\Omega$，对于其中任一事件$A$，定义函数$P$，满足以下三大公理：</p>
<ul>
<li><p>非负性公理：</p>
<script type="math/tex; mode=display">
  P(A)\ge 0</script></li>
<li><p>规范性公理：</p>
<script type="math/tex; mode=display">
  P(\Omega) = 1</script></li>
<li><p>可加性公理：<br>  设$A_1、A_2、\cdots$为两两不相容的事件，即$A_i\cap A_j=\varnothing（i\ne j）$，有：</p>
<script type="math/tex; mode=display">
  P(A_1\cup A_2\cup\cdots) = P(A_1)+P(A_2)+\cdots</script></li>
</ul>
<p>则$P$称为概率函数，$P(A)$称为事件 A 的概率。</p>
<h2 id="事件之间的运算和关系"><a href="#事件之间的运算和关系" class="headerlink" title="事件之间的运算和关系"></a>事件之间的运算和关系</h2><ul>
<li><p>并运算：<br>  对于事件$A、B$，并运算定义为（$\equiv$表示定义）：</p>
<script type="math/tex; mode=display">
  A\cup B\equiv\{x|x\in A\ 或 \ x\in B\}</script></li>
<li><p>交运算：<br>  对于事件$A、B$，交运算定义为：</p>
<script type="math/tex; mode=display">
  A\cap B\equiv\{x|x\in A\ 且 \ x\in B\}</script></li>
<li><p>差运算：<br>  对于事件$A、B$，定义差运算为：</p>
<script type="math/tex; mode=display">
  A-B\equiv\{x|x\in A\quad 且、quad x\notin B\}</script></li>
<li><p>补运算：<br>  对于事件 A、B，如果：</p>
<script type="math/tex; mode=display">
  A=\Omega-B</script><p>  则称 B 为 A 的补，记作（其中 c 代表 Complement）：</p>
<script type="math/tex; mode=display">
  B=\overline{A}\quad 或、quad B=A^c</script></li>
<li><p>基本运算的性质：</p>
<script type="math/tex; mode=display">
\begin{array}{c|c|c}
  \hline
  \quad\quad&\quad  类比、quad&\quad 改写 \quad\\
  \hline
  \\
  \quad 并 \quad&\quad  +\quad&\quad A\cup B=A+B \quad\\
  \quad 交 \quad&\quad  \times\quad&\quad A\cap B=AB \quad\\ 
  \quad 差 \quad&\quad  -\quad&\quad A-B \quad\\
  \\
  \hline
\end{array}</script></li>
<li><p>德摩根定律：</p>
<script type="math/tex; mode=display">
  \overline{A\cup B}=\overline{A}\cap\overline{B}</script><p>  \overline{A\cap B}=\overline{A}\cup\overline{B}<br>  $$</p>
</li>
<li><p>小结：</p>
<script type="math/tex; mode=display">
\begin{array}{c|c|c}
  \hline
  \quad\quad&\quad 定义、quad&\quad 类比、quad\\
  \hline
  \\
  \quad 并 \quad&\quad A\cup B=\{x|x\in A\ 或 \ x\in B\}\quad&\quad  +\quad\\
  \quad 交 \quad&\quad A\cap B=\{x|x\in A\ 且 \ x\in B\}\quad&\quad  \times\quad\\ 
  \quad 差 \quad&\quad A-B=\{x|x\in A\ 且、x\notin B\}\quad&\quad  -\quad\\
  \quad 补 \quad&\quad \overline{A}=B\iff B=\Omega - A\\
  \\
  \hline
\end{array}</script></li>
<li><p>事件之间的关系：</p>
</li>
</ul>
<script type="math/tex; mode=display">
事件之间的关系=
\begin{cases}
    包含、\
    相等、\
    不相容、\
    对立
\end{cases}</script><h2 id="条件概率"><a href="#条件概率" class="headerlink" title="条件概率"></a>条件概率</h2><p>设 A 和 B 是样本空间$\Omega$中的两事件，若$P(B) &gt; 0$，则称：</p>
<script type="math/tex; mode=display">
P(A|B)=\frac{P(A\cap B)}{P(B)}</script><p>为“假设条件为 B 时的 A 的概率”，简称条件概率。也常写作：</p>
<script type="math/tex; mode=display">
P(A|B)=\frac{P(AB)}{P(B)}</script><h4 id="乘法公式"><a href="#乘法公式" class="headerlink" title="乘法公式"></a>乘法公式</h4><ul>
<li><p>若$P(B) &gt; 0$，则：</p>
<script type="math/tex; mode=display">
  P(AB)=P(\color{Orange}{B})P(A|\color{Orange}{B})</script></li>
<li><p>若$P(A) &gt; 0$，则：</p>
<script type="math/tex; mode=display">
  P(AB)=P(\color{Magenta}{A})P(B|\color{Magenta}{A})</script></li>
<li><p>若$P(A_1\cdots A_n) &gt; 0$，则：</p>
<script type="math/tex; mode=display">
  P(A_1\cdots A_n)=P(A_1)P(A_2|A_1)P(A_3|A_1A_2)\cdots P(A_n|A_1\cdots A_{n-1})</script></li>
</ul>
<p>63 4、 贝叶斯与全概率<br>对于同一样本空间$\Omega$中的随机事件$A、B$，若$P(B) \ne 0$，有：</p>
<script type="math/tex; mode=display">
P(A|B)=\frac{P(A)}{P(B)}P(B|A)</script><p>设$A_1、A_2、\cdots、A_n$满足：</p>
<script type="math/tex; mode=display">
A_i\cap A_j=\varnothing , (i\ne j)\quad 且、quad P(\bigcup_{i=1}^{n}A_i)=1</script><p>若$P(A_i) &gt; 0,i=1,2,\cdots,n$，则对任意事件$B$有：</p>
<script type="math/tex; mode=display">
P(B)=\sum_{i=1}^{n}P(A_i)P(B|A_i)</script><p>有了全概率公式后，可以得到贝叶斯定理真正的样子：<br>设$A_1、A_2、\cdots、A_n$为样本空间$\Omega$的一个分割，则有：</p>
<script type="math/tex; mode=display">
\begin{aligned}
    P(A_i|B)
        &=\frac{P(BA_i)}{P(B)}\\
        \\
        &=\frac{P(B|A_i)}{P(B)}P(A_i)\\
        \\
        &=\frac{P(B|A_i)}{\displaystyle\sum_{i=1}^{n}P(A_i)P(B|A_i)}P(A_i)
\end{aligned}</script><p>也就是把$P(B)$分解到分割$A_1、A_2、\cdots、A_n$上去了。</p>
<h2 id="独立事件"><a href="#独立事件" class="headerlink" title="独立事件"></a>独立事件</h2><p>对于两个随机事件$A、B$，如果满足：</p>
<script type="math/tex; mode=display">
P(AB)=P(A)P(B)</script><p>则称 A 与 B 相互独立，或简称 A 与 B 独立，否则称 A 与 B 不独立或相依。</p>
<p>设$A<em>1、A_2、\cdots$为有限个或者无限个事件，从中任取两个$A</em>{i1}、A_{i2}$，若满足：</p>
<script type="math/tex; mode=display">
P(A_{i1}A_{i2})=P(A_{i1})P(A_{i2})</script><p>则称$A_1、A_2、\cdots$是两两独立。</p>
<p>若从中任取有限个$A<em>{j1}、A</em>{j2}、\cdots、A_{jm}$，若满足：</p>
<script type="math/tex; mode=display">
P(A_{j1}A_{j2}\cdots A_{jm})=P(A_{j1})P(A_{j2})\cdots P(A_{jm})</script><p>则称$A_1、A_2、\cdots$是相互独立。</p>
<h1 id="随机变量及其分布"><a href="#随机变量及其分布" class="headerlink" title="随机变量及其分布"></a>随机变量及其分布</h1><h2 id="随机变量"><a href="#随机变量" class="headerlink" title="随机变量"></a>随机变量</h2><p>定义在样本空间$\Omega$上的实值函数：</p>
<script type="math/tex; mode=display">
X=X(\omega),\quad \omega\in\Omega</script><p>称为随机变量。随机变量是一个函数，所以都用大写字母来表示，以示和自变量 x 的区别。</p>
<h2 id="二项分布"><a href="#二项分布" class="headerlink" title="二项分布"></a>二项分布</h2><h4 id="概率质量函数"><a href="#概率质量函数" class="headerlink" title="概率质量函数"></a>概率质量函数</h4><p>如果$p(x)$满足$（x\in {x_i},i=1,2,\cdots）$：</p>
<ul>
<li><p>非负性：</p>
<script type="math/tex; mode=display">
  p(x_i) \ge 0</script></li>
<li><p>规范性：</p>
<script type="math/tex; mode=display">
  \sum_{i=1}^{\infty}p(x_i)=1</script></li>
</ul>
<p>则称其为概率质量函数（PMF）。</p>
<h4 id="伯努利分布"><a href="#伯努利分布" class="headerlink" title="伯努利分布"></a>伯努利分布</h4><p>某样本空间只包含两个元素，$\Omega={\omega_1,\omega_2}$，在其上定义随机变量$X$：</p>
<script type="math/tex; mode=display">
X=X(\omega)=
\begin{cases}
1,&\omega=\omega_1\\
0,&\omega=\omega_2
\end{cases}</script><p>若$0\le p\le 1$时，有：</p>
<script type="math/tex; mode=display">
p(1)=P(X=1)=p</script><script type="math/tex; mode=display">
p(0)=P(X=0)=1-p</script><p>或写作：</p>
<script type="math/tex; mode=display">
P(X=x)=p(x)=
\begin{cases}
p,&x=1\\
1-p,&x=0 
\end{cases}</script><p>则此概率分布称作 0-1 分布，也称作伯努利分布。</p>
<p>在数学中，类似于扔一次硬币这样的“是非题”称为一次伯努利试验，像上面这样独立地重复扔 n 次硬币（做同样的“是非题”n 次），就称为 n 重伯努利试验。</p>
<h3 id="二项分布-1"><a href="#二项分布-1" class="headerlink" title="二项分布"></a>二项分布</h3><p>对于 n 重伯努利实验，如果每次得到“是”的概率为 p，设随机变量：</p>
<script type="math/tex; mode=display">
X=得到“是”的次数</script><p>则称：</p>
<script type="math/tex; mode=display">
p(k)=P(X=k)={n\choose k}p^k(1-p)^{n-k},\quad k=0,1,\cdots,n</script><p>为随机变量 X 的二项分布，也可以记作：</p>
<script type="math/tex; mode=display">
X\sim b(n,p)</script><p>当 n=1 的时候，对应的就是伯努利分布，所以伯努利分布也可以记作$b(1,p)$。</p>
<h3 id="离散的累积分布函数"><a href="#离散的累积分布函数" class="headerlink" title="离散的累积分布函数"></a>离散的累积分布函数</h3><p>设$X$是一个随机变量，$x$是任意实数，函数： </p>
<script type="math/tex; mode=display">
F(x)=P(X \le x)=\sum_{a\le x}p(a)</script><p>因为是把概率质量函数累加起来，所以称为累积分布函数（Cumulative Distribution Function，或者缩写为 CDF），也简称为分布函数。</p>
<p> 离散的数学期望<br>设离散随机变量$X$的概率质量函数为：</p>
<script type="math/tex; mode=display">
p(x_i)=P(X=x_i),i=1,2,\cdots,n,\cdots</script><p>如果：</p>
<script type="math/tex; mode=display">
\sum_{i=1}^{\infty}|x_i|p(x_i) < \infty</script><p>则称：</p>
<script type="math/tex; mode=display">
E(X)=\sum_{i=1}^{\infty}x_ip(x_i)</script><p>为随机变量 X 的数学期望（expected value，或，expectation），简称期望或均值（mean），也有很多文档会用$\mu_X$来表示（如果不强调随机变量的话，也可以直接用$\mu$来表示）：</p>
<script type="math/tex; mode=display">
\mu_X=\mu=\sum_{i=1}^{\infty}x_ip(x_i)</script><p>若级数$\sum_{i=1}^{\infty}|x_i|p(x_i)$不收敛，则称$X$的数学期望不存在。</p>
<p>学期望也称作矩。更准确点说，由于数学期望：</p>
<script type="math/tex; mode=display">
E(X)=\sum_{i=1}^{\infty}x_ip(x_i)</script><p>中$x_i$是一次项，所以又称作一阶矩。这个称呼经常在统计的书上会遇到，特在此说明。</p>
<h4 id="数学期望的性质"><a href="#数学期望的性质" class="headerlink" title="数学期望的性质"></a>数学期望的性质</h4><ul>
<li><p>复合：<br>  假设$g(X)$为随机变量$X$的某一函数，则：</p>
<script type="math/tex; mode=display">
  E\left[g(X)\right]=\sum_i g(x_i)p(x_i)</script></li>
<li><p>常数：<br>  若 c 为常数，则：</p>
<script type="math/tex; mode=display">
  E(c)=c</script></li>
<li><p>线性组合：<br>  数学期望满足：</p>
<ul>
<li>齐次性，对于任意常数$a$有：<script type="math/tex; mode=display">
E(aX)=aE(X)</script></li>
<li>可加性，对于随机变量的函数$g_1(X)、g_2(X)$有：<script type="math/tex; mode=display">
E\left[g_1(X)+g_2(X)\right]=E\left[g_1(X)\right]+E\left[g_2(X)\right]</script></li>
</ul>
</li>
<li><p>伯努利分布和二项分布的期望分别如下：</p>
<script type="math/tex; mode=display">
\begin{array}{c|c}
  &\qquad 伯努利分布、qquad&\qquad 二项分布、qquad\\
  \hline\\
  \ PMF\ & p(x)=\begin{cases}p,&x=1\\1-p,&x=0\end{cases} & p(x)={n\choose x}p^x(1-p)^{n-x}\\\\
  \hline \\
  \quad \mu\quad& p & np \\
\end{array}</script></li>
</ul>
<h2 id="方差与标准差"><a href="#方差与标准差" class="headerlink" title="方差与标准差"></a>方差与标准差</h2><h3 id="方差"><a href="#方差" class="headerlink" title="方差"></a>方差</h3><p>代数式：</p>
<script type="math/tex; mode=display">
Var(X)=E\left[\Big(X-E(X)\Big)^2\right]</script><p>称为随机变量 X 的方差（Variance），也可记作$\sigma^2$或者$\sigma_X^2$。</p>
<h3 id="方差的性质"><a href="#方差的性质" class="headerlink" title="方差的性质"></a>方差的性质</h3><ul>
<li><p>化简：<br>  可以通过下式来化简运算：</p>
<script type="math/tex; mode=display">
  Var(X)=E\left(X^2\right)-\mu^2</script></li>
<li><p>常数：<br>  若 c 为常数，则：</p>
<script type="math/tex; mode=display">
  Var(c)=0</script></li>
<li><p>相加与数乘：<br>  若 a、b 为常数，则：</p>
<script type="math/tex; mode=display">
  Var(aX+b)=a^2Var(X)</script></li>
</ul>
<h3 id="标准差"><a href="#标准差" class="headerlink" title="标准差"></a>标准差</h3><p>假如随机变量$X$的方差为$Var(X)$，则称：</p>
<script type="math/tex; mode=display">
\sigma(X)=\sqrt{Var(X)}</script><p>为标准差，也可以记作$\sigma$或者$\sigma_X$。</p>
<h3 id="二项分布的方差"><a href="#二项分布的方差" class="headerlink" title="二项分布的方差"></a>二项分布的方差</h3><script type="math/tex; mode=display">
\begin{array}{c|c}
    &\qquad 伯努利分布、qquad&\qquad 二项分布、qquad\\
    \hline
    \\
    \ PMF\ & p(x)=\begin{cases}p,&x=1\\1-p,&x=0\end{cases} & p(x)={n\choose x}p^x(1-p)^{n-x}\\
    \\
    \hline
    \\
    \quad \mu\quad& p & np \\
    \\
    \hline 
    \\
    \quad Var(X)\quad& p(1-p) & np(1-p) \\
    \\
\end{array}</script><h3 id="马尔可夫不等式"><a href="#马尔可夫不等式" class="headerlink" title="马尔可夫不等式"></a>马尔可夫不等式</h3><p>设$X$为取非负值的随机变量，则对于任何$a &gt; 0$，有：</p>
<script type="math/tex; mode=display">
P(X\ge a)\le \frac{E(X)}{a}</script><h3 id="切比雪夫不等式"><a href="#切比雪夫不等式" class="headerlink" title="切比雪夫不等式"></a>切比雪夫不等式</h3><p>设$X$是一随机变量，均值$\mu$和方差$\sigma^2$有限，则对任何$k &gt; 0$有： </p>
<script type="math/tex; mode=display">
P(|X-\mu| \ge k)\le \frac{\sigma^2}{k^2}</script><h2 id="泊松分布"><a href="#泊松分布" class="headerlink" title="泊松分布"></a>泊松分布</h2><p>对于随机变量$X$的概率质量函数：</p>
<script type="math/tex; mode=display">
P(X=k)=\frac{\lambda^k}{k!}e^{-\lambda},\quad k=0,1,2,\cdots</script><p>称为随机变量$X$的泊松分布，也可以记为：</p>
<script type="math/tex; mode=display">
X\sim P(\lambda)</script><p>其数学期望和方差为：</p>
<script type="math/tex; mode=display">
E(X)=\lambda,\quad Var(X)=\lambda</script><p><strong>条件</strong><br>更一般地，在某一段时间 T 内发生特定事件的次数，如果满足以下假设，都可以看作泊松分布：</p>
<ul>
<li>平稳性：在此时间段 T 内，此事件发生的概率相同（在实际应用中大致相同就可以了）。</li>
<li>独立性：事件的发生彼此之间独立（或者说，关联性很弱）。</li>
<li>普通性：把 T 切分成足够小的区间、Delta T，在、Delta T 内恰好发生两个、或多个事件的可能性为 0（或者说，几乎为 0）。</li>
</ul>
<p>泊松分布是二项分布的极限：</p>
<script type="math/tex; mode=display">
\lim_{n\to\infty}{n\choose k}\left(\frac{\mu}{n}\right)^k\left(1-\frac{\mu}{n}\right)^{n-k}=\frac{\mu^k}{k!}e^{-\mu}</script><p>所以在泊松分布的$\lambda$固定的情况，二项分布的 n 越大（对应的$p=\frac{\lambda}{n}$越小），此时两者会非常接近。</p>
<h2 id="重要的离散分部"><a href="#重要的离散分部" class="headerlink" title="重要的离散分部"></a>重要的离散分部</h2><h3 id="几何分布"><a href="#几何分布" class="headerlink" title="几何分布"></a>几何分布</h3><p>对于 n 重伯努利实验，如果每次得到“是”的概率为 p，设随机变量：</p>
<script type="math/tex; mode=display">
X=首次得到“是”时进行的试验次数</script><p>则称：</p>
<script type="math/tex; mode=display">
p(k)=P(X=k)=(1-p)^{k-1}p,\quad k=1,2,\cdots</script><p>为随机变量 X 的几何分布，也可以记作：</p>
<script type="math/tex; mode=display">
X\sim Ge(p)</script><p>其数学期望和方差为：</p>
<script type="math/tex; mode=display">
E(X)=\frac{1}{p},\quad Var(X)=\frac{1-p}{p^2}</script><h3 id="负二项分布"><a href="#负二项分布" class="headerlink" title="负二项分布"></a>负二项分布</h3><p>对于 n 重伯努利实验，如果每次得到“是”的概率为 p，设随机变量：</p>
<script type="math/tex; mode=display">
X=第 r 次“是”发生时的实验次数</script><p>则称：</p>
<script type="math/tex; mode=display">
p(k)=P(X=k)={k-1\choose r-1}p^r(1-p)^{k-r},k=r,r+1,\cdots</script><p>为随机变量 X 的负二项分布，也称为帕斯卡分布，也可以记作：</p>
<script type="math/tex; mode=display">
X\sim Nb(r,p)</script><p>其数学期望为：</p>
<script type="math/tex; mode=display">
E(X)=\frac{r}{p},\quad Var(X)=\frac{r(1-p)}{p^2}</script><h3 id="负二项分布与几何分布"><a href="#负二项分布与几何分布" class="headerlink" title="负二项分布与几何分布"></a>负二项分布与几何分布</h3><ul>
<li><p>几何是负二项的特例 ：<br>  负二项分布是这样的：</p>
<script type="math/tex; mode=display">
  p(k)=P(X=k)={k-1\choose r-1}p^r(1-p)^{k-r},k=r,r+1,\cdots</script><p>  r=1 的时候，就得到了几何分布：</p>
<script type="math/tex; mode=display">
  p(k)=P(X=k)=(1-p)^{k-1}p,\quad k=1,2,\cdots</script></li>
<li><p>负二项是几何的和：<br>  参数为 r、p 的负二项分布可以表示为如下事件序列：<br>  <img src="https://lsky.carlyleliu.vip/carlyleliu/ImageHosting/TechnologyBlog/Science/Math/negativeBinomial.png" alt=""><br>  图中所示的每一段$X_1、X_2、\cdots、X_r$都是几何分布，所以有：</p>
<script type="math/tex; mode=display">
  X=X_1+X_2+\cdots+X_r\sim Nb(r,p)</script><p>  所以负二项分布的期望为：</p>
<script type="math/tex; mode=display">
  E(X)=E(X_1)+E(X_2)+\cdots+E(X_r)=\frac{r}{p}</script></li>
</ul>
<h3 id="超几何分布"><a href="#超几何分布" class="headerlink" title="超几何分布"></a>超几何分布</h3><p>设有 N 件产品，其中有 M 件不合格品，随机抽取 n 件产品，则其中含有 m 件不合格产品的概率为多少？<br>假设随机变量：</p>
<script type="math/tex; mode=display">
X=随机抽取的 n 件中有 m 件不合格品</script><p>这个随机变量的概率可以用古典概率来求，首先，样本空间就是从 N 件中随便抽取 n 件，所以：</p>
<script type="math/tex; mode=display">
|\Omega| = {N\choose n}</script><p>然后有 m 件从不合格品中抽取，剩下的在合格品中抽取，则有：</p>
<script type="math/tex; mode=display">
|X| = {M\choose m}{N-M\choose n-m}</script><p>所求概率即为：</p>
<script type="math/tex; mode=display">
P(X=m)=\frac{\left(\begin{array}{c}
M \\
m
\end{array}\right)\left(\begin{array}{c}
N-M \\
n-m
\end{array}\right)}{\left(\begin{array}{c}
N \\
n
\end{array}\right)}, m=0,1, \cdots, r</script><p>其中$r=min(M,n)$。此时称 X 服从超几何分布，可以记作：</p>
<script type="math/tex; mode=display">
X\sim h(n,N,M)</script><p>其数学期望和方差为：</p>
<script type="math/tex; mode=display">
E(X)=n\frac{M}{N},\quad Var(X)=n\frac{M}{N}\left(1-\frac{M}{N}\right)\left(1-\frac{n-1}{N-1}\right)</script><h3 id="超几何分布与二项分布"><a href="#超几何分布与二项分布" class="headerlink" title="超几何分布与二项分布"></a>超几何分布与二项分布</h3><p>超几何分布与二项分布类似，都是求抽取 n 次其中有 m 次“是”的概率，只是：</p>
<ul>
<li>二项分布：相当于抽取之后放回。</li>
<li>超几何分布：抽取之后不放回。</li>
</ul>
<p>所以在超几何分布中，如果被抽取的总数 N 特别大，那么放回不放回区别也就不大了，此时，那么超几何分布可以近似看作二项分布。<br>这点从两者的期望、方差也可以看出来：</p>
<script type="math/tex; mode=display">
\begin{array}{c|c}
    &\qquad 二项分布、qquad&\qquad 超几何分布、qquad\\
    \hline
    \\
    \quad \mu\quad& np & n\frac{M}{N} \\
    \\
    \hline 
    \\
    \quad \sigma^2\quad& np(1-p) & n\frac{M}{N}\left(1-\frac{M}{N}\right)\left(1-\frac{n-1}{N-1}\right)\\
    \\
\end{array}</script><p>令$p=\frac{M}{N}$，超几何分布的期望和方差可以写作：</p>
<script type="math/tex; mode=display">
\mu=n\frac{M}{N}=np</script><p>\sigma^2=n\frac{M}{N}\left(1-\frac{M}{N}\right)\left(1-\frac{n-1}{N-1}\right)=np(1-p)\left(1-\frac{n-1}{N-1}\right)</p>
<script type="math/tex; mode=display">

对超几何分布而言，当 N 足够大的时候，$\frac{M}{N}$可看作取出不合格产品的概率，那此时超几何分布可看作二项分布。

### 总结</script><p>\begin{array}{c|c}<br>    \hline<br>    \<br>    \quad 伯努利分布、quad&amp;\quad 抛硬币，二选一 \quad\<br>    \quad 二项分布、quad&amp;\quad n 重伯努利，出现 k 次“是” \quad\<br>    \quad 泊松分布、quad&amp;\quad 二项分布的极限 \quad\<br>    \quad 几何分布、quad&amp;\quad n 重伯努利，第 k 次首次出现“是” \quad\<br>    \quad 负二项分布、quad&amp;\quad 几何分布的和 \quad\<br>    \quad 超几何分布、quad&amp;\quad 不放回抽样的二项分布 \quad\<br>    \<br>    \hline<br>\end{array}</p>
<script type="math/tex; mode=display">

## 概率密度函数
### 概率密度函数
如果函数$p(x)$满足下列两个条件（对应了概率的三大公理）：

- 非负性：</script><pre><code>p(x) \ge 0
$$
</code></pre><ul>
<li>规范性（暗含了可加性），因为是连续的，所以通过积分相加：<script type="math/tex; mode=display">
  \int_{-\infty}^{+\infty}p(x)\mathrm{d}x=1</script></li>
</ul>
<p>则称其为概率密度函数（Probability Density Function，简写为 PDF）。</p>
<h3 id="期望"><a href="#期望" class="headerlink" title="期望"></a>期望</h3><p>离散随机变量的期望定义为：</p>
<script type="math/tex; mode=display">
E(X)=\sum_{i=1}^{\infty}x_ip(x_i)</script><p>可以用类似的方法定义连续随机变量的期望，当然期望的意义是没有改变的：</p>
<script type="math/tex; mode=display">
E(X)=\int_{-\infty}^{+\infty}xp(x)\mathrm{d}x</script><p>关于期望的几个性质也是成立的：</p>
<ul>
<li><p>复合：<br>  假设$g(X)$为连续随机变量$X$的某一函数，则：</p>
<script type="math/tex; mode=display">
  E\left[g(X)\right]=\int_{-\infty}^{+\infty}g(x)p(x)\mathrm{d}x</script></li>
<li><p>常数：<br>  若 c 为常数，则：</p>
<script type="math/tex; mode=display">
  E(c)=c</script></li>
<li><p>线性：<br>  数学期望满足：</p>
<ul>
<li>齐次性，对于任意常数 a 有：<script type="math/tex; mode=display">
E(aX)=aE(X)</script></li>
<li>可加性，对于任意两个函数$g_1(X)、g_2(X)$有：<script type="math/tex; mode=display">
E\left[g_1(X)+g_2(X)\right]=E\left[g_1(X)\right]+E\left[g_2(X)\right]</script></li>
</ul>
</li>
</ul>
<h3 id="方差-1"><a href="#方差-1" class="headerlink" title="方差"></a>方差</h3><p>方差的定义依然是：</p>
<script type="math/tex; mode=display">
Var(X)=E\left[\Big(X-E(X)\Big)^2\right]</script><p>相关的性质也是成立的：</p>
<ul>
<li><p>化简：<br>  可以通过下式来化简运算：</p>
<script type="math/tex; mode=display">
  Var(X)=E\left(X^2\right)-\mu^2</script></li>
<li><p>常数：<br>  若 c 为常数，则：</p>
<script type="math/tex; mode=display">
  Var(c)=0</script></li>
<li><p>相加与数乘：<br>  若 a、b 为常数，则：</p>
<script type="math/tex; mode=display">
  Var(aX+b)=a^2Var(X)</script></li>
</ul>
<h3 id="累积分布函数"><a href="#累积分布函数" class="headerlink" title="累积分布函数"></a>累积分布函数</h3><p>连续随机变量$X$的概率密度函数为$p(x)$，则：</p>
<script type="math/tex; mode=display">
F(x)=P(X \le x)=\int_{-\infty}^{x}p(t)\mathrm{d}t</script><p>称为$X$的累积分布函数。</p>
<h2 id="正态分布"><a href="#正态分布" class="headerlink" title="正态分布"></a>正态分布</h2><h3 id="正态分布-1"><a href="#正态分布-1" class="headerlink" title="正态分布"></a>正态分布</h3><p>如果连续随机变量$X$的概率密度函数为：</p>
<script type="math/tex; mode=display">
p(x)=\frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{(x-\mu)^2}{2\sigma^2}},\quad -\infty < x < +\infty</script><p>则称$X$服从正态分布（normal distribution），也称作高斯分布（Gaussian distribution），记作$X\sim N(\mu,\sigma^2)$，其累积分布函数为：</p>
<script type="math/tex; mode=display">
F(x)=\frac{1}{\sigma\sqrt{2\pi}}\int_{-\infty}^{x}e^{-\frac{(t-\mu)^2}{2\sigma^2}}\mathrm{d}t</script><p>我们称$\mu=0、\sigma=1$时的正态分布$N(0,1)$为标准正态分布。</p>
<h3 id="期望与方差"><a href="#期望与方差" class="headerlink" title="期望与方差"></a>期望与方差</h3><p>正态分布$X\sim N(\mu,\sigma^2)$的期望和方差为：</p>
<script type="math/tex; mode=display">
E(X)=\mu,\quad Var(X)=\sigma^2</script><h2 id="指数分布"><a href="#指数分布" class="headerlink" title="指数分布"></a>指数分布</h2><p>若随机变量$X$的概率密度函数为：</p>
<script type="math/tex; mode=display">
p(x)=\begin{cases}
\lambda e^{-\lambda x}, & x \ge 0\\
0,& x < 0
\end{cases}</script><p>其中$\lambda &gt; 0$，称$X$服从指数分布，也可以记为：</p>
<script type="math/tex; mode=display">
X\sim Exp(\lambda)</script><p>累积分布函数为：</p>
<script type="math/tex; mode=display">
F(x)=\begin{cases}
1-e^{-\lambda x}, & x \ge 0\\
0,& x < 0
\end{cases}</script><p>指数分布$X\sim Exp(\lambda)$的期望和方差为：</p>
<script type="math/tex; mode=display">
E(X)=\frac{1}{\lambda},\quad Var(X)=\frac{1}{\lambda^2}</script><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>首先是一维离散随机变量的概率分布：</p>
<script type="math/tex; mode=display">
\begin{array}{c|c}
    \hline
    \\
    \quad 伯努利分布、quad&\quad 抛硬币，二选一 \quad\\ 
    \quad 二项分布、quad&\quad n 重伯努利，出现 k 次“是” \quad\\ 
    \quad 泊松分布、quad&\quad 二项分布的极限 \quad\\ 
    \quad 几何分布、quad&\quad n 重伯努利，第 k 次首次出现“是” \quad\\ 
    \quad 负二项分布、quad&\quad 几何分布的和 \quad\\ 
    \quad 超几何分布、quad&\quad 不放回抽样的二项分布 \quad\\ 
    \\
    \hline
\end{array}</script><p>然后是一维连续随机变量的概率分布：</p>
<script type="math/tex; mode=display">
\begin{array}{c|c}
    \hline
    \\
    \quad 均匀分布、quad&\quad 古典派中的几何概型 \quad\\ 
    \quad 正态分布、quad&\quad 二项分布的另外一种极限 \quad\\ 
    \quad 指数分布、quad&\quad 泊松分布的间隔，连续的几何分布 \quad\\ 
    \\
    \hline
\end{array}</script><h1 id="多维随机变量及其分布"><a href="#多维随机变量及其分布" class="headerlink" title="多维随机变量及其分布"></a>多维随机变量及其分布</h1><h2 id="多维随机变量及其分布-1"><a href="#多维随机变量及其分布-1" class="headerlink" title="多维随机变量及其分布"></a>多维随机变量及其分布</h2><h3 id="联合概率质量函数"><a href="#联合概率质量函数" class="headerlink" title="联合概率质量函数"></a>联合概率质量函数</h3><p>如果二维随机向量$(X,Y)$所有可能的取值为$(x_i,y_j),i,j=1,2,\cdots$，这两个随机变量同时发生的概率可以用函数表示如下：</p>
<script type="math/tex; mode=display">
p_{ij}=P(X=x_i,Y=y_j)=P(X=x_i\ \color{red}{且}\ Y=y_j),\quad i,j=1,2,\cdots</script><p>且此函数满足如下性质（即概率的三大公理）：</p>
<ul>
<li><p>非负性：</p>
<script type="math/tex; mode=display">
  p_{ij}\ge 0</script></li>
<li><p>规范性和可加性：</p>
<script type="math/tex; mode=display">
  \sum_{i=1}^{\infty}\sum_{j=1}^{\infty}p_{ij}=1</script></li>
</ul>
<p>则称此函数为$(X,Y)$的联合概率质量函数（Joint Probability Mass Function），或者称为联合分布列，此定义可以推广到多维离散随机变量上去。</p>
<h3 id="联合概率密度函数"><a href="#联合概率密度函数" class="headerlink" title="联合概率密度函数"></a>联合概率密度函数</h3><p>对于某二维随机变量$(X,Y)$存在二元函数$p(x,y)$满足：</p>
<ul>
<li><p>非负性：</p>
<script type="math/tex; mode=display">
  p(x,y)\ge 0</script></li>
<li><p>规范性和可加性（连续的都通过积分来相加）：</p>
<script type="math/tex; mode=display">
  \int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty}p(x,y)\mathrm{d}x\mathrm{d}y=1</script></li>
</ul>
<p>则称此函数为$(X,Y)$的联合概率密度函数（Joint Probability Density Function），此定义可以推广到多维连续随机变量上去。</p>
<h3 id="联合累积分布函数"><a href="#联合累积分布函数" class="headerlink" title="联合累积分布函数"></a>联合累积分布函数</h3><p>设$(X,Y)$是二维随机变量，对于任意实数$x、y$，可以定义一个二元函数来表示两个事件同时发生的概率： </p>
<script type="math/tex; mode=display">
F(x,y)=P\Big(\{X\le x\}\ \color{red}{且}\ \{Y\le y\}\Big)=P(X\le x, Y\le y)</script><p>称为二维随机变量$(X,Y)$的联合累积分布函数（Joint Cumulative Distribution Function），如果混合偏导存在的话，那么：</p>
<script type="math/tex; mode=display">
\frac{\partial F(x,y)}{\partial x \partial y}=p(x,y)</script><p>得到$p(x,y)$就是此分布的概率密度函数。此定义和性质可以推广到多维随机变量。</p>
<h3 id="多维均匀分布"><a href="#多维均匀分布" class="headerlink" title="多维均匀分布"></a>多维均匀分布</h3><p>设$D$为$R^n$中的一个有界区域，其度量（直线为长度，平面为面积，空间为体积等）为$S_D$，如果多维随机变量$(X_1,X_2,\cdots,X_n)$的联合概率密度函数为：</p>
<script type="math/tex; mode=display">
p(x_1,x_2,\cdots,x_n)=
\begin{cases}
    \frac{1}{S_D},&(x_1,x_2,\cdots,x_n)\in D\\
    0,&其它
\end{cases}</script><p>则称$(X_1,X_2,\cdots,X_n)$服从$D$上的多维均匀分布，记作：</p>
<script type="math/tex; mode=display">
(X_1,X_2,\cdots,X_n)\sim U(D)</script><h2 id="边缘分布与随机变量的独立性"><a href="#边缘分布与随机变量的独立性" class="headerlink" title="边缘分布与随机变量的独立性"></a>边缘分布与随机变量的独立性</h2><h3 id="边缘概率质量函数"><a href="#边缘概率质量函数" class="headerlink" title="边缘概率质量函数"></a>边缘概率质量函数</h3><p>如果二维离散随机变量$(X,Y)$的联合概率质量函数为：</p>
<script type="math/tex; mode=display">
P(X=x_i,Y=y_j),i,j=1,2,\cdots</script><p>对$j$求和所得的函数：</p>
<script type="math/tex; mode=display">
\sum_{j=1}^{\infty}P(X=x_i,Y=y_j)=P(X=x_i)</script><p>称为$X$的边缘概率质量函数（Marginal Probability Mass Function），或者称为边缘分布列。类似的对 i 求和所得的函数：</p>
<script type="math/tex; mode=display">
\sum_{i=1}^{\infty}P(X=x_i,Y=y_j)=P(Y=y_j)</script><p>称为$Y$的边缘概率质量函数。</p>
<h3 id="边缘概率密度函数"><a href="#边缘概率密度函数" class="headerlink" title="边缘概率密度函数"></a>边缘概率密度函数</h3><p>如果二维连续随机变量$(X,Y)$的联合概率密度函数为$p(x,y)$，则：</p>
<script type="math/tex; mode=display">
p_X(x)=\int_{-\infty}^{+\infty}p(x,y)\mathrm{d}y</script><p>称为$X$的边缘概率密度函数（Marginal Probability Density Function）。类似的：</p>
<script type="math/tex; mode=display">
p_Y(y)=\int_{-\infty}^{+\infty}p(x,y)\mathrm{d}x</script><p>称为 Y 的边缘概率密度函数。</p>
<h3 id="边缘累积分布函数"><a href="#边缘累积分布函数" class="headerlink" title="边缘累积分布函数"></a>边缘累积分布函数</h3><p>如果二维连续随机变量$(X,Y)$的联合累积分布函数为$F(x,y)$，如下可以得到$X$的累积分布函数：</p>
<script type="math/tex; mode=display">
F_X(x)=\lim_{y\to+\infty}F(x,y)=P(X\le x,Y < +\infty)=P(X\le x)</script><p>称为$X$的边缘累积分布函数（Marginal Cumulative Distribution Function）。可记作：</p>
<script type="math/tex; mode=display">
F_X(x)=F(x,+\infty)</script><p>同理可以得到 Y 的边缘累积分布函数：</p>
<script type="math/tex; mode=display">
F_Y(y)=F(+\infty, y)</script><h2 id="条件分布"><a href="#条件分布" class="headerlink" title="条件分布"></a>条件分布</h2><h3 id="离散的条件分布"><a href="#离散的条件分布" class="headerlink" title="离散的条件分布"></a>离散的条件分布</h3><p>设$(X,Y)$是二维离散型随机变量，对于固定的$j$，若$P(Y=y_j)\ge 0$，则称：</p>
<script type="math/tex; mode=display">
P\left(X=x_{i} | Y=y_{j}\right)=\frac{P\left(X=x_{i}, Y=y_{j}\right)}{P\left(Y=y_{j}\right)}, i=1,2, \cdots</script><p>为$Y=y_j$条件下的随机变量$X$的条件概率质量函数。同样的对于固定的$i$，若$P(X=x_i)\ge 0$，则称：</p>
<script type="math/tex; mode=display">
P\left(Y=y_{j} | X=x_{i}\right)=\frac{P\left(X=x_{i}, Y=y_{j}\right)}{P\left(X=x_{i}\right)}, j=1,2, \cdots</script><p>为$X=x_i$条件下的随机变量$Y$的条件概率质量函数。</p>
<p>条件分布和条件概率没有什么区别，一样可以用于全概率公式、贝叶斯公式。</p>
<h3 id="连续的条件分布"><a href="#连续的条件分布" class="headerlink" title="连续的条件分布"></a>连续的条件分布</h3><p>设二维连续型随机变量$(X,Y)$的概率密度函数为$p(x,y)$，若对于固定的$y$有边缘概率密度函数$p_Y(y) &gt; 0$，则：</p>
<script type="math/tex; mode=display">
p_{X|Y}(x\ |\ y)=\frac{p(x,y)}{p_Y(y)}</script><p>为$Y=y$条件下的随机变量$X$的条件概率密度函数。对应的条件累积分布函数为：</p>
<script type="math/tex; mode=display">
F_{X|Y}(x\ |\ y)=\int_{-\infty}^{x}\frac{p(u,y)}{p_Y(y)}\mathrm{d}u</script><p>同样的道理，以$X=x$为条件有：</p>
<script type="math/tex; mode=display">
p_{Y|X}(y\ |\ x)=\frac{p(x,y)}{p_X(x)}</script><p>F<em>{Y|X}(y\ |\ x)=\int</em>{-\infty}^{y}\frac{p(x,u)}{p_X(x)}\mathrm{d}u</p>
<script type="math/tex; mode=display">

### 连续的全概率和贝叶斯

- 全概率：</script><pre><code>p_{Y}(y)=\int_{-\infty}^{+\infty} p(y | x) p_{X}(x) \mathrm{d} x
$$
p_{X}(x)=\int_{-\infty}^{+\infty} p(x | y) p_{Y}(y) \mathrm{d} y
$$
</code></pre><ul>
<li>贝叶斯：<script type="math/tex; mode=display">
\begin{aligned} 
  p(x | y) 
      &=\frac{p(y | x) p_{X}(x)}{p_{Y}(y)} \\
      &=\frac{p(y | x) p_{X}(x)}{\int_{-\infty}^{+\infty} p(y | x) p_{X}(x) \mathrm{d} x} 
\end{aligned}</script></li>
</ul>
<h2 id="多维随机变量函数的分布"><a href="#多维随机变量函数的分布" class="headerlink" title="多维随机变量函数的分布"></a>多维随机变量函数的分布</h2><h3 id="随机变量的和"><a href="#随机变量的和" class="headerlink" title="随机变量的和"></a>随机变量的和</h3><ul>
<li><p>离散：<br>  设 X、Y 为两个相互独立的离散随机变量，取值范围为$0，1，2，\cdots$，则其和的概率质量函数为：</p>
<script type="math/tex; mode=display">
  P(X+Y=k)=\sum_{i=0}^{k}P(X=i)P(Y=k-i)</script><p>  这个概率等式称为离散场合下的卷积公式。</p>
</li>
<li><p>连续：<br>  设$(X,Y)$为二维连续型随机变量，概率密度函数为$p(x,y)$，则$Z=X+Y$仍为连续型随机变量，其概率密度为：</p>
<script type="math/tex; mode=display">
  p_{X+Y}(z)=\int_{-\infty}^{+\infty}p(z-y,y)\mathrm{d}y=\int_{-\infty}^{+\infty}p(x,z-x)\mathrm{d}x</script><p>  若$X、Y$为相互独立，其边缘密度函数分别为$p_X(x)$和$p_Y(y)$，则其和$Z=X+Y$的概率密度函数为：</p>
<script type="math/tex; mode=display">
  p_Z(z)=\int_{-\infty}^{+\infty}p_X(z-y)p_Y(y)\mathrm{d}y=\int_{-\infty}^{+\infty}p_X(x)p_Y(z-x)\mathrm{d}x</script><p>  上面两个概率等式称为连续场合下的卷积公式。</p>
</li>
</ul>
<h1 id="随机变量的数字特征"><a href="#随机变量的数字特征" class="headerlink" title="随机变量的数字特征"></a>随机变量的数字特征</h1><h2 id="数学期望"><a href="#数学期望" class="headerlink" title="数学期望"></a>数学期望</h2><h3 id="数学期望的定义"><a href="#数学期望的定义" class="headerlink" title="数学期望的定义"></a>数学期望的定义</h3><p>离散随机变量的数学期望定义为：</p>
<script type="math/tex; mode=display">
E(X)=\sum_{i=1}^{\infty}x_ip(x_i)</script><p>连续随机变量的数学期望定义为：</p>
<script type="math/tex; mode=display">
E(X)=\int_{-\infty}^{+\infty}xp(x)\mathrm{d}x</script><h3 id="函数的数学期望"><a href="#函数的数学期望" class="headerlink" title="函数的数学期望"></a>函数的数学期望</h3><ul>
<li><p>一维随机变量：<br>  设$Y$是随机变量$X$的函数$Y=g(X)$(g 是连续函数）。</p>
<ul>
<li>若$X$为离散随机变量，则（设下式中的级数绝对收敛）：<script type="math/tex; mode=display">
E(Y)=E\left[g(X)\right]=\sum_i g(x_i)p(x_i)</script></li>
<li>若$X$为连续随机变量，则（设下式中的积分绝对收敛）：<script type="math/tex; mode=display">
E(Y)=E\left[g(X)\right]=\int_{-\infty}^{+\infty}g(x)p(x)\mathrm{d}x</script></li>
</ul>
</li>
<li><p>多维随机变量：<br>  设$Z$是随机变量$(X,Y)$的函数$Z=g(X,Y)$(g 是连续函数）。</p>
<ul>
<li>若$(X,Y)$为离散随机变量，则（设下式中的级数绝对收敛）：<script type="math/tex; mode=display">
E(Z)=E\left[g(X,Y)\right]=\sum_j\sum_i g(x_i,y_j)p(x_i,y_j)</script></li>
<li>若$(X,Y)$为连续随机变量，则（设下式中的积分绝对收敛）：<script type="math/tex; mode=display">
E(Z)=E\left[g(X,Y)\right]=\int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty}g(x,y)p(x,y)\mathrm{d}x\mathrm{d}y</script></li>
</ul>
</li>
</ul>
<h3 id="线性的数学期望"><a href="#线性的数学期望" class="headerlink" title="线性的数学期望"></a>线性的数学期望</h3><p>数学期望满足：</p>
<ul>
<li><p>齐次性，对于任意常数 a 有：</p>
<script type="math/tex; mode=display">
  E(aX)=aE(X)</script></li>
<li><p>可加性，对于任意两个函数$g_1(X)、g_2(X)$有：</p>
<script type="math/tex; mode=display">
  E\left[g_1(X)+g_2(X)\right]=E\left[g_1(X)\right]+E\left[g_2(X)\right]</script></li>
</ul>
<p>对于多维也成立：</p>
<script type="math/tex; mode=display">
E(X+Y)=E(X)+E(Y)</script><p>E(X_1+X_2+\cdots+X_n)=E(X_1)+E(X_2)+\cdots+E(X_n)</p>
<script type="math/tex; mode=display">

### 施瓦茨不等式
对任意随机变量$X$与$Y$都有：</script><p>\Big[E(XY)\Big]^2 \le E(X^2)E(Y^2)</p>
<script type="math/tex; mode=display">

### 独立的数学期望
设$(X,Y)$为二维独立随机变量，则有：</script><p>E(XY)=E(X)E(Y)</p>
<script type="math/tex; mode=display">
这个结论可以推广到 n 维独立随机变量：</script><p>E\left(X<em>{1} X</em>{2} \cdots X<em>{n}\right)=E\left(X</em>{1}\right) E\left(X<em>{2}\right) \cdots E\left(X</em>{n}\right)</p>
<script type="math/tex; mode=display">

## 方差与标准差
### 方差与标准差的定义
方差定义为（因为直接通过数学期望定义的，所以没有区分离散和连续）：</script><p>Var(X)=E\left[\Big(X-E(X)\Big)^2\right]</p>
<script type="math/tex; mode=display">

为了写的简单一点，也常常令$E(X)=\mu$，那么上式可以改写为：</script><p>Var(X)=E\left[(X-\mu)^2\right]</p>
<script type="math/tex; mode=display">

之前也介绍过，由于方差里面含有平方，在实际应用中需要开平方才能保持单位一致，这就是标准差：</script><p>\sigma(X)=\sqrt{Var(X)}</p>
<script type="math/tex; mode=display">

### 线性的方差
若$a、b$为常数，则：</script><p>Var(aX+b)=a^2Var(X)</p>
<script type="math/tex; mode=display">

### 独立的方差
设$(X,Y)$为二维独立随机变量，则有：</script><p>Var(X\pm Y)=Var(X)+Var(Y)</p>
<script type="math/tex; mode=display">

这个结论可以推广到 n 维独立随机变量：</script><p>Var\left(X<em>{1}\pm X</em>{2}\pm \cdots\pm X<em>{n}\right)=Var\left(X</em>{1}\right) +Var\left(X<em>{2}\right)+\cdots+Var\left(X</em>{n}\right)</p>
<script type="math/tex; mode=display">

## 协方差
### 协方差的定义
设$(X,Y)$是一个二维随机变量，若$E\Big[(X-\mu_X)(Y-\mu_Y)\Big]$存在，则称此数学期望为$X$与$Y$的协方差（Covariance），记作：</script><p>Cov(X,Y)=E\Big[(X-\mu_X)(Y-\mu_Y)\Big]</p>
<script type="math/tex; mode=display">

特别地有$Cov(X,X)=Var(X)$。

很显然会有：

- $Cov(X,Y) > 0$时，$X、Y$正相关，即两者有同时增加或者减少的倾向。
- $Cov(X,Y) < 0$时，$X、Y$负相关，即两者有反向增加或者减少的倾向。
- $Cov(X,Y) = 0$时，$X、Y$不相关，不过和独立还是有区别的，这点我们后面再论述。

### 协方差的性质

- 化简：
    可以通过下式来化简运算：</script><pre><code>Cov(X,Y)=E(XY)-E(X)E(Y)
$$
据此马上可以得到一个推论：
$$
Cov(X,Y)=Cov(Y,X)
$$
</code></pre><ul>
<li><p>方差：<br>  对于任意的二维随机变量$(X,Y)$有：</p>
<script type="math/tex; mode=display">
  Var(X+Y)=Var(X)+Var(Y)+2Cov(X,Y)</script><p>  Var(X-Y)=Var(X)+Var(Y)-2Cov(X,Y)</p>
<script type="math/tex; mode=display">
  所以当$(X,Y)$为二维不相关随机变量时，有：</script><p>  Var(X\pm Y)=Var(X)+Var(Y)<br>  $$</p>
</li>
<li><p>分配律：</p>
<script type="math/tex; mode=display">
  Cov(X_1+X_2,Y)=Cov(X_1, Y)+Cov(X_2,Y)</script></li>
<li><p>数乘：</p>
<script type="math/tex; mode=display">
  Cov(aX+c,bY+d)=abCov(X, Y)</script></li>
</ul>
<h3 id="独立与不相关"><a href="#独立与不相关" class="headerlink" title="独立与不相关"></a>独立与不相关</h3><ul>
<li><p>独立必不相关：<br>  根据刚才的性质：</p>
<script type="math/tex; mode=display">
  Cov(X,Y)=E(XY)-E(X)E(Y)</script><p>  如果 X、Y 独立，则有：</p>
<script type="math/tex; mode=display">
  E(XY)=E(X)E(Y)\implies Cov(X,Y)=0</script><p>  所以：</p>
<script type="math/tex; mode=display">
  独立、implies 不相关</script></li>
<li><p>不相关不能推出独立：<br>  不相关只能说明 X、Y 之间没有正相关规律，也没有负相关规律，但可能还有很多别的规律，所以：</p>
<script type="math/tex; mode=display">
  不相关、\mathrel{\rlap{\hskip .5em/}}\Longrightarrow\ 独立</script></li>
</ul>
<h3 id="相关系数"><a href="#相关系数" class="headerlink" title="相关系数"></a>相关系数</h3><p>对于二维随机变量$(X,Y)$，各自的方差为：</p>
<script type="math/tex; mode=display">
Var(X)=\sigma^2_X,\quad Var(Y)=\sigma^2_Y</script><p>则：</p>
<script type="math/tex; mode=display">
\rho_{XY}=\frac{Cov(X,Y)}{\sigma_X\sigma_Y}</script><p>称为随机变量$X$和$Y$的相关系数。</p>
<p>对于任意的二维随机变量$(X,Y)$，若相关系数存在，则：</p>
<script type="math/tex; mode=display">
-1\le\rho_{XY}\le 1</script><p>有界性让比较有了一个范围，我们可以得到如下结论：</p>
<ul>
<li>$\rho &gt; 0$：正相关，且$\rho=1$的时候，正相关性最大，称为完全正相关。</li>
<li>$\rho &lt; 0$：负相关，且$\rho=-1$的时候，负相关性最大，称为完全负相关。</li>
<li>$\rho = 0$：不相关。</li>
</ul>
<h3 id="二维正态分布"><a href="#二维正态分布" class="headerlink" title="二维正态分布"></a>二维正态分布</h3><p>如果二维随机变量$(X,Y)$的联合概率密度函数为：</p>
<script type="math/tex; mode=display">
\begin{aligned} 
    p(x, y)=
        & \frac{1}{2 \pi \sigma_{1} \sigma_{2} \sqrt{1-\rho^{2}}} \exp \left\{-\frac{1}{2\left(1-\rho^{2}\right)}\left[\frac{\left(x-\mu_{1}\right)^{2}}{\sigma_{1}^{2}}\right.\right.\\ 
        &-\frac{2 \rho\left(x-\mu_{1}\right)\left(y-\mu_{2}\right)}{\sigma_{1} \sigma_{2}}+\frac{\left(y-\mu_{2}\right)^{2}}{\sigma_{2}^{2}} ] \} 
\end{aligned}</script><p>则称$(X,Y)$服从二维正态分布，记作：</p>
<script type="math/tex; mode=display">
(X,Y)\sim N(\mu_1,\mu_2,\sigma_1^2,\sigma_2^2,\rho)</script><p>它含有五个参数$\mu_1，\mu_2，\sigma_1^2，\sigma_2^2$和$\rho$，取值范围分别为：</p>
<script type="math/tex; mode=display">
-\infty<\mu_{1}<\infty,-\infty<\mu_{2}<\infty, \sigma_{1}>0, \sigma_{2}>0,-1 \leqslant \rho \leqslant 1</script><p>并且$\mu_1，\mu_2$分别是$X、Y$的期望；$\sigma_1^2，\sigma_2^2$分别是$X、Y$的方差；$\rho$是$X、Y$的相关系数。</p>
<h1 id="大数定律及中心极限定理"><a href="#大数定律及中心极限定理" class="headerlink" title="大数定律及中心极限定理"></a>大数定律及中心极限定理</h1><h2 id="大数定律"><a href="#大数定律" class="headerlink" title="大数定律"></a>大数定律</h2><h3 id="伯努利大数定律"><a href="#伯努利大数定律" class="headerlink" title="伯努利大数定律"></a>伯努利大数定律</h3><p>整个概率论的得以存在的基础是，其所研究的随机现象虽然结果不确定，但又有规律可循。这个基础在概率论中被称为大数定律（Law of large numbers）。大数定律是一系列的定律，先来介绍伯努利大数定律：</p>
<p>设$n_A$是$n$次重复独立实验中事件$A$发生的次数，$p$是事件$A$在每次实验中发生的概率，则对于任意正数$\epsilon &gt; 0$，有：</p>
<script type="math/tex; mode=display">
\lim_{n\to \infty}P\left(\left|\frac{n_\text{A}}{n}-p\right| < \epsilon \right) = 1</script><p>或：</p>
<script type="math/tex; mode=display">
\lim_{n\to \infty}P\left(\left|\frac{n_\text{A}}{n}-p\right| \ge \epsilon \right) = 0</script><p>这里需要注意不能直接用：</p>
<script type="math/tex; mode=display">
\lim_{n\to \infty}\frac{n_\text{H}}{n}=p</script><p>而必须在外面套上一个概率函数，$\frac{n_\text{H}}{n}$并不是一个数列，而是随机变量。因此它不具备进行极限运算的前提。</p>
<h3 id="依概率收敛"><a href="#依概率收敛" class="headerlink" title="依概率收敛"></a>依概率收敛</h3><p>因为$\frac{n_\text{H}}{n}$是随机变量，所以要表示它和$p$接近，只能表示为事件：</p>
<script type="math/tex; mode=display">
“频率 P_n 越来越接近概率 p”=\Big\{\left|\frac{n_\text{H}}{n}-p\right| < \epsilon\Big\}</script><p>然后套上概率函数$P$，对该函数求$n$趋于无穷时的极限：</p>
<script type="math/tex; mode=display">
\lim_{n\to \infty}P\left(\left|\frac{n_\text{H}}{n}-p\right| < \epsilon \right) = 1</script><p>这个极限同样表达了“随着$n$的增大，频率$P_n$会越来越接近概率$p$”的意思，但是因为套上了概率函数，所以也称为$P_n$依概率收敛于$p$，记作：</p>
<script type="math/tex; mode=display">
\frac{n_\text{H}}{n}\xrightarrow{\quad P \quad}p,\quad n\to\infty</script><h3 id="辛钦大数定律"><a href="#辛钦大数定律" class="headerlink" title="辛钦大数定律"></a>辛钦大数定律</h3><p>伯努利大数定律局限于伯努利分布，下面介绍辛钦大数定律就没有这个限制，只是要求遵循相同的分布：<br>设有随机变量：</p>
<script type="math/tex; mode=display">
X_1,X_2,\cdots,X_n</script><p>这些随机变量相互独立，服从同一分布，且具有相同的数学期望：</p>
<script type="math/tex; mode=display">
E(X_i)=\mu,\quad i=1,2,\cdots,n</script><p>令：</p>
<script type="math/tex; mode=display">
\overline{X}=\frac{X_1+X_2+\cdots+X_n}{n}</script><p>则对于任意$\epsilon &gt; 0$有：</p>
<script type="math/tex; mode=display">
\lim_{n\to \infty}P\left(\left|\overline{X}-\mu\right| < \epsilon \right) = 1</script><p>或：</p>
<script type="math/tex; mode=display">
\lim_{n\to \infty}P\left(\left|\overline{X}-\mu\right| \ge \epsilon \right) = 0</script><p>也可以表述为：</p>
<script type="math/tex; mode=display">
\overline{X}\xrightarrow{\quad P \quad}\mu,\quad n\to\infty</script><h3 id="切比雪夫大数定律"><a href="#切比雪夫大数定律" class="headerlink" title="切比雪夫大数定律"></a>切比雪夫大数定律</h3><p>相同的分布也算比较严格的限制，下面介绍切比雪夫大数定律对于分布就更加宽松，只要各自的方差有共同上界即可：<br>设有随机变量：</p>
<script type="math/tex; mode=display">
X_1,X_2,\cdots,X_n</script><p>这些随机变量两两不相关，若每个随机变量$X_i$的方差存在，且有共同的上界，即：</p>
<script type="math/tex; mode=display">
Var(X_i)\le c,\quad i=1,2,\cdots,n</script><p>令：</p>
<script type="math/tex; mode=display">
\overline{X}=\frac{X_1+X_2+\cdots+X_n}{n},\quad \mu=E(\overline{X})</script><p>则对于任意$\epsilon &gt; 0$有：</p>
<script type="math/tex; mode=display">
\lim_{n\to \infty}P\left(\left|\overline{X}-\mu\right| < \epsilon \right) = 1</script><p>或：</p>
<script type="math/tex; mode=display">
\lim_{n\to \infty}P\left(\left|\overline{X}-\mu\right| \ge \epsilon \right) = 0</script><p>也可以表述为：</p>
<script type="math/tex; mode=display">
\overline{X}\xrightarrow{\quad P \quad}\mu,\quad n\to\infty</script><h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h3><p>这里总共介绍了三个大数定律，主要区别如下：</p>
<script type="math/tex; mode=display">
\begin{array}{c|c}
    \hline
    \quad \quad &\quad 分布、quad&\quad 独立性、quad&\quad 方差、quad\\
    \hline
    \\
    \quad 伯努利大数、quad & \quad 伯努利分布、quad & \quad 独立、quad & \quad 无要求、quad\\
    辛钦大数 & 同分布 & 独立 & 无要求 \\
    切比雪夫大数 & 无要求 & 不相关 & 同上界、\
    \\
    \hline
\end{array}</script><h3 id="强大数定律"><a href="#强大数定律" class="headerlink" title="强大数定律"></a>强大数定律</h3><p>前面介绍的大数定律又称为弱大数定律（Weak Law of large numbers），有弱就自然就有强，下面就来介绍强大数定律（Strong Law of large numbers）：<br>设有随机变量：</p>
<script type="math/tex; mode=display">
X_1,X_2,\cdots,X_n</script><p>这些随机变量相互独立，服从同一分布，且具有相同的数学期望：</p>
<script type="math/tex; mode=display">
E(X_i)=\mu,\quad i=1,2,\cdots,n</script><p>令：</p>
<script type="math/tex; mode=display">
\overline{X}=\frac{X_1+X_2+\cdots+X_n}{n}</script><p>则对于任意$\epsilon &gt; 0$有：</p>
<script type="math/tex; mode=display">
P\left(\lim_{n\to \infty}\left|\overline{X}-\mu\right| < \epsilon \right) = 1</script><p>或：</p>
<script type="math/tex; mode=display">
P\left(\lim_{n\to \infty}\left|\overline{X}-\mu\right| \ge \epsilon \right) = 0</script><p>这个强大数定律和之前的辛钦大数定律非常接近：</p>
<ul>
<li><p>弱大数定律（辛钦大数定律），极限符号在 P 函数外面：</p>
<script type="math/tex; mode=display">
\lim_{n\to \infty}P\left(\left|\overline{X}-\mu\right| < \epsilon \right) = 1</script></li>
<li><p>强大数定律，极限符号在 P 函数里面：</p>
<script type="math/tex; mode=display">
P\left(\lim_{n\to \infty}\left|\overline{X}-\mu\right| < \epsilon \right) = 1</script><p>仔细体会这两则之间的区别^ _ ^。</p>
</li>
</ul>
<h2 id="中心极限定理"><a href="#中心极限定理" class="headerlink" title="中心极限定理"></a>中心极限定理</h2><h3 id="棣莫弗-拉普拉斯定理"><a href="#棣莫弗-拉普拉斯定理" class="headerlink" title="棣莫弗-拉普拉斯定理"></a>棣莫弗-拉普拉斯定理</h3><p>设随机变量$X\sim b(n,p)$，则对任意 x 有： </p>
<script type="math/tex; mode=display">
\lim_{n\to\infty}P\left(\frac{X-np}{\sqrt{np(1-p)}}\le x\right)=\Phi(x)=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{x}e^{-\frac{t^2}{2}}\mathrm{d}t</script><h3 id="林德伯格-莱维定理"><a href="#林德伯格-莱维定理" class="headerlink" title="林德伯格-莱维定理"></a>林德伯格-莱维定理</h3><p>设随机变量：</p>
<script type="math/tex; mode=display">
X_i,\quad i=1,2,\cdots,n</script><p>相互独立，服从同一分布，且有相同的数学期望和方差：</p>
<script type="math/tex; mode=display">
E(X_i)=\mu,\quad Var(X_i)=\sigma^2</script><p>则随机变量：</p>
<script type="math/tex; mode=display">
Y=\frac{X_1+X_2+\cdots+X_n-n\mu}{\sigma\sqrt{n}}</script><p>对于任意实数$y$有： </p>
<script type="math/tex; mode=display">
\lim_{n\to\infty}F_Y(y)=\lim_{n\to\infty}P(Y\le y)=\Phi(y)=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{y}e^{-\frac{t^2}{2}}\mathrm{d}t</script><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>《马同学的概率论与数理统计》<br>感兴趣的可以购买他的课程，写的很好（强烈推荐）！！！  </p>
</article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Math/">Math</a><a class="post-meta__tags" href="/tags/Linear-Algebra/">Linear Algebra</a></div><div class="post_share"><div class="social-share" data-image="https://unsplash.it/1600/900?random&amp;7417" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/Debug/oops/" title="一个 oops 分析实例"><img class="cover" src="https://unsplash.it/1600/900?random&amp;9647" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">一个 oops 分析实例</div></div></a></div><div class="next-post pull-right"><a href="/Science/linearAlgebra/" title="线性代数"><img class="cover" src="https://unsplash.it/1600/900?random&amp;4809" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">线性代数</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/Science/CalculusPart1/" title="微积分（上）"><img class="cover" src="https://unsplash.it/1600/900?random&8455" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-03-08</div><div class="title">微积分（上）</div></div></a></div><div><a href="/Science/CalculusPart2/" title="微积分（下）"><img class="cover" src="https://unsplash.it/1600/900?random&5266" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-03-10</div><div class="title">微积分（下）</div></div></a></div><div><a href="/Science/linearAlgebra/" title="线性代数"><img class="cover" src="https://unsplash.it/1600/900?random&4809" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-03-13</div><div class="title">线性代数</div></div></a></div><div><a href="/Science/NaturalLanguageProcessing/" title="自然语言处理"><img class="cover" src="https://unsplash.it/1600/900?random&9275" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-04-06</div><div class="title">自然语言处理</div></div></a></div><div><a href="/Science/QuadraticEquation/" title="高次方程的解"><img class="cover" src="https://unsplash.it/1600/900?random&7876" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-03-23</div><div class="title">高次方程的解</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">CarlyleLiu</div><div class="author-info__description">CarlyleLiu’s Blog</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">194</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">42</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">28</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/carlyleliu"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/carlyleliu" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:yyliushuai@gmail.com" target="_blank" title="E-Mail"><i class="fa fa-envelope" style="color: #24292e;"></i></a><a class="social-icon" href="https://twitter.com/yyliushuai" target="_blank" title="Twitter"><i class="fab fa-twitter" style="color: #24292e;"></i></a><a class="social-icon" href="https://youtube.com/carlyleliu" target="_blank" title="YouTube"><i class="fab fa-youtube" style="color: #24292e;"></i></a><a class="social-icon" href="https://instagram.com/blurredliu" target="_blank" title="Instagram"><i class="fab fa-instagram" style="color: #24292e;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">next主题站 https://carlyleliu.github.io/next</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%A6%82%E7%8E%87%E8%AE%BA%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5"><span class="toc-number">1.</span> <span class="toc-text">概率论基本概念</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A6%82%E7%8E%87%E7%9A%84%E6%B4%BE%E5%88%AB"><span class="toc-number">1.1.</span> <span class="toc-text">概率的派别</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A6%82%E7%8E%87%E5%85%AC%E7%90%86%E5%8C%96"><span class="toc-number">1.2.</span> <span class="toc-text">概率公理化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8B%E4%BB%B6%E4%B9%8B%E9%97%B4%E7%9A%84%E8%BF%90%E7%AE%97%E5%92%8C%E5%85%B3%E7%B3%BB"><span class="toc-number">1.3.</span> <span class="toc-text">事件之间的运算和关系</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9D%A1%E4%BB%B6%E6%A6%82%E7%8E%87"><span class="toc-number">1.4.</span> <span class="toc-text">条件概率</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B9%98%E6%B3%95%E5%85%AC%E5%BC%8F"><span class="toc-number">1.4.0.1.</span> <span class="toc-text">乘法公式</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%8B%AC%E7%AB%8B%E4%BA%8B%E4%BB%B6"><span class="toc-number">1.5.</span> <span class="toc-text">独立事件</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83"><span class="toc-number">2.</span> <span class="toc-text">随机变量及其分布</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F"><span class="toc-number">2.1.</span> <span class="toc-text">随机变量</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E9%A1%B9%E5%88%86%E5%B8%83"><span class="toc-number">2.2.</span> <span class="toc-text">二项分布</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A6%82%E7%8E%87%E8%B4%A8%E9%87%8F%E5%87%BD%E6%95%B0"><span class="toc-number">2.2.0.1.</span> <span class="toc-text">概率质量函数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BC%AF%E5%8A%AA%E5%88%A9%E5%88%86%E5%B8%83"><span class="toc-number">2.2.0.2.</span> <span class="toc-text">伯努利分布</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%8C%E9%A1%B9%E5%88%86%E5%B8%83-1"><span class="toc-number">2.2.1.</span> <span class="toc-text">二项分布</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%A6%BB%E6%95%A3%E7%9A%84%E7%B4%AF%E7%A7%AF%E5%88%86%E5%B8%83%E5%87%BD%E6%95%B0"><span class="toc-number">2.2.2.</span> <span class="toc-text">离散的累积分布函数</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E5%AD%A6%E6%9C%9F%E6%9C%9B%E7%9A%84%E6%80%A7%E8%B4%A8"><span class="toc-number">2.2.2.1.</span> <span class="toc-text">数学期望的性质</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%96%B9%E5%B7%AE%E4%B8%8E%E6%A0%87%E5%87%86%E5%B7%AE"><span class="toc-number">2.3.</span> <span class="toc-text">方差与标准差</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%B9%E5%B7%AE"><span class="toc-number">2.3.1.</span> <span class="toc-text">方差</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%B9%E5%B7%AE%E7%9A%84%E6%80%A7%E8%B4%A8"><span class="toc-number">2.3.2.</span> <span class="toc-text">方差的性质</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A0%87%E5%87%86%E5%B7%AE"><span class="toc-number">2.3.3.</span> <span class="toc-text">标准差</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%8C%E9%A1%B9%E5%88%86%E5%B8%83%E7%9A%84%E6%96%B9%E5%B7%AE"><span class="toc-number">2.3.4.</span> <span class="toc-text">二项分布的方差</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E4%B8%8D%E7%AD%89%E5%BC%8F"><span class="toc-number">2.3.5.</span> <span class="toc-text">马尔可夫不等式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%87%E6%AF%94%E9%9B%AA%E5%A4%AB%E4%B8%8D%E7%AD%89%E5%BC%8F"><span class="toc-number">2.3.6.</span> <span class="toc-text">切比雪夫不等式</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B3%8A%E6%9D%BE%E5%88%86%E5%B8%83"><span class="toc-number">2.4.</span> <span class="toc-text">泊松分布</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%87%8D%E8%A6%81%E7%9A%84%E7%A6%BB%E6%95%A3%E5%88%86%E9%83%A8"><span class="toc-number">2.5.</span> <span class="toc-text">重要的离散分部</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%87%A0%E4%BD%95%E5%88%86%E5%B8%83"><span class="toc-number">2.5.1.</span> <span class="toc-text">几何分布</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B4%9F%E4%BA%8C%E9%A1%B9%E5%88%86%E5%B8%83"><span class="toc-number">2.5.2.</span> <span class="toc-text">负二项分布</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B4%9F%E4%BA%8C%E9%A1%B9%E5%88%86%E5%B8%83%E4%B8%8E%E5%87%A0%E4%BD%95%E5%88%86%E5%B8%83"><span class="toc-number">2.5.3.</span> <span class="toc-text">负二项分布与几何分布</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B6%85%E5%87%A0%E4%BD%95%E5%88%86%E5%B8%83"><span class="toc-number">2.5.4.</span> <span class="toc-text">超几何分布</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B6%85%E5%87%A0%E4%BD%95%E5%88%86%E5%B8%83%E4%B8%8E%E4%BA%8C%E9%A1%B9%E5%88%86%E5%B8%83"><span class="toc-number">2.5.5.</span> <span class="toc-text">超几何分布与二项分布</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%9F%E6%9C%9B"><span class="toc-number">2.5.6.</span> <span class="toc-text">期望</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%B9%E5%B7%AE-1"><span class="toc-number">2.5.7.</span> <span class="toc-text">方差</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%B4%AF%E7%A7%AF%E5%88%86%E5%B8%83%E5%87%BD%E6%95%B0"><span class="toc-number">2.5.8.</span> <span class="toc-text">累积分布函数</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83"><span class="toc-number">2.6.</span> <span class="toc-text">正态分布</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83-1"><span class="toc-number">2.6.1.</span> <span class="toc-text">正态分布</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%9F%E6%9C%9B%E4%B8%8E%E6%96%B9%E5%B7%AE"><span class="toc-number">2.6.2.</span> <span class="toc-text">期望与方差</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8C%87%E6%95%B0%E5%88%86%E5%B8%83"><span class="toc-number">2.7.</span> <span class="toc-text">指数分布</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">2.7.0.1.</span> <span class="toc-text">总结</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%A4%9A%E7%BB%B4%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83"><span class="toc-number">3.</span> <span class="toc-text">多维随机变量及其分布</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%9A%E7%BB%B4%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83-1"><span class="toc-number">3.1.</span> <span class="toc-text">多维随机变量及其分布</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%81%94%E5%90%88%E6%A6%82%E7%8E%87%E8%B4%A8%E9%87%8F%E5%87%BD%E6%95%B0"><span class="toc-number">3.1.1.</span> <span class="toc-text">联合概率质量函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%81%94%E5%90%88%E6%A6%82%E7%8E%87%E5%AF%86%E5%BA%A6%E5%87%BD%E6%95%B0"><span class="toc-number">3.1.2.</span> <span class="toc-text">联合概率密度函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%81%94%E5%90%88%E7%B4%AF%E7%A7%AF%E5%88%86%E5%B8%83%E5%87%BD%E6%95%B0"><span class="toc-number">3.1.3.</span> <span class="toc-text">联合累积分布函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E7%BB%B4%E5%9D%87%E5%8C%80%E5%88%86%E5%B8%83"><span class="toc-number">3.1.4.</span> <span class="toc-text">多维均匀分布</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BE%B9%E7%BC%98%E5%88%86%E5%B8%83%E4%B8%8E%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E7%8B%AC%E7%AB%8B%E6%80%A7"><span class="toc-number">3.2.</span> <span class="toc-text">边缘分布与随机变量的独立性</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BE%B9%E7%BC%98%E6%A6%82%E7%8E%87%E8%B4%A8%E9%87%8F%E5%87%BD%E6%95%B0"><span class="toc-number">3.2.1.</span> <span class="toc-text">边缘概率质量函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BE%B9%E7%BC%98%E6%A6%82%E7%8E%87%E5%AF%86%E5%BA%A6%E5%87%BD%E6%95%B0"><span class="toc-number">3.2.2.</span> <span class="toc-text">边缘概率密度函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BE%B9%E7%BC%98%E7%B4%AF%E7%A7%AF%E5%88%86%E5%B8%83%E5%87%BD%E6%95%B0"><span class="toc-number">3.2.3.</span> <span class="toc-text">边缘累积分布函数</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9D%A1%E4%BB%B6%E5%88%86%E5%B8%83"><span class="toc-number">3.3.</span> <span class="toc-text">条件分布</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%A6%BB%E6%95%A3%E7%9A%84%E6%9D%A1%E4%BB%B6%E5%88%86%E5%B8%83"><span class="toc-number">3.3.1.</span> <span class="toc-text">离散的条件分布</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%9E%E7%BB%AD%E7%9A%84%E6%9D%A1%E4%BB%B6%E5%88%86%E5%B8%83"><span class="toc-number">3.3.2.</span> <span class="toc-text">连续的条件分布</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%9A%E7%BB%B4%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%87%BD%E6%95%B0%E7%9A%84%E5%88%86%E5%B8%83"><span class="toc-number">3.4.</span> <span class="toc-text">多维随机变量函数的分布</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E5%92%8C"><span class="toc-number">3.4.1.</span> <span class="toc-text">随机变量的和</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E6%95%B0%E5%AD%97%E7%89%B9%E5%BE%81"><span class="toc-number">4.</span> <span class="toc-text">随机变量的数字特征</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E5%AD%A6%E6%9C%9F%E6%9C%9B"><span class="toc-number">4.1.</span> <span class="toc-text">数学期望</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E5%AD%A6%E6%9C%9F%E6%9C%9B%E7%9A%84%E5%AE%9A%E4%B9%89"><span class="toc-number">4.1.1.</span> <span class="toc-text">数学期望的定义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%87%BD%E6%95%B0%E7%9A%84%E6%95%B0%E5%AD%A6%E6%9C%9F%E6%9C%9B"><span class="toc-number">4.1.2.</span> <span class="toc-text">函数的数学期望</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BA%BF%E6%80%A7%E7%9A%84%E6%95%B0%E5%AD%A6%E6%9C%9F%E6%9C%9B"><span class="toc-number">4.1.3.</span> <span class="toc-text">线性的数学期望</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%8B%AC%E7%AB%8B%E4%B8%8E%E4%B8%8D%E7%9B%B8%E5%85%B3"><span class="toc-number">4.1.4.</span> <span class="toc-text">独立与不相关</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0"><span class="toc-number">4.1.5.</span> <span class="toc-text">相关系数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%8C%E7%BB%B4%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83"><span class="toc-number">4.1.6.</span> <span class="toc-text">二维正态分布</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%A4%A7%E6%95%B0%E5%AE%9A%E5%BE%8B%E5%8F%8A%E4%B8%AD%E5%BF%83%E6%9E%81%E9%99%90%E5%AE%9A%E7%90%86"><span class="toc-number">5.</span> <span class="toc-text">大数定律及中心极限定理</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%A7%E6%95%B0%E5%AE%9A%E5%BE%8B"><span class="toc-number">5.1.</span> <span class="toc-text">大数定律</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%AF%E5%8A%AA%E5%88%A9%E5%A4%A7%E6%95%B0%E5%AE%9A%E5%BE%8B"><span class="toc-number">5.1.1.</span> <span class="toc-text">伯努利大数定律</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BE%9D%E6%A6%82%E7%8E%87%E6%94%B6%E6%95%9B"><span class="toc-number">5.1.2.</span> <span class="toc-text">依概率收敛</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BE%9B%E9%92%A6%E5%A4%A7%E6%95%B0%E5%AE%9A%E5%BE%8B"><span class="toc-number">5.1.3.</span> <span class="toc-text">辛钦大数定律</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%87%E6%AF%94%E9%9B%AA%E5%A4%AB%E5%A4%A7%E6%95%B0%E5%AE%9A%E5%BE%8B"><span class="toc-number">5.1.4.</span> <span class="toc-text">切比雪夫大数定律</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%BB%E7%BB%93-1"><span class="toc-number">5.1.5.</span> <span class="toc-text">总结</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BC%BA%E5%A4%A7%E6%95%B0%E5%AE%9A%E5%BE%8B"><span class="toc-number">5.1.6.</span> <span class="toc-text">强大数定律</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%AD%E5%BF%83%E6%9E%81%E9%99%90%E5%AE%9A%E7%90%86"><span class="toc-number">5.2.</span> <span class="toc-text">中心极限定理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A3%A3%E8%8E%AB%E5%BC%97-%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E5%AE%9A%E7%90%86"><span class="toc-number">5.2.1.</span> <span class="toc-text">棣莫弗-拉普拉斯定理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9E%97%E5%BE%B7%E4%BC%AF%E6%A0%BC-%E8%8E%B1%E7%BB%B4%E5%AE%9A%E7%90%86"><span class="toc-number">5.2.2.</span> <span class="toc-text">林德伯格-莱维定理</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE"><span class="toc-number">6.</span> <span class="toc-text">参考文献</span></a></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2018 - 2025 By CarlyleLiu</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=4.13.0"></script></div></div><!-- hexo injector body_end start --><script data-pjax>
  function butterfly_footer_beautify_injector_config(){
    var parent_div_git = document.getElementById('footer-wrap');
    var item_html = '<p id="ghbdages"><a class="github-badge" target="_blank" href="https://hexo.io/" style="margin-inline:5px" data-title="博客框架为Hexo" title=""><img src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&amp;logo=hexo" alt=""/></a><a class="github-badge" target="_blank" href="https://butterfly.js.org/" style="margin-inline:5px" data-title="主题版本Butterfly" title=""><img src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&amp;logo=bitdefender" alt=""/></a><a class="github-badge" target="_blank" href="https://github.com/" style="margin-inline:5px" data-title="本站项目由Github托管" title=""><img src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&amp;logo=GitHub" alt=""/></a><a class="github-badge" target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" style="margin-inline:5px" data-title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可" title=""><img src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&amp;logo=Claris" alt=""/></a></p>';
    console.log('已挂载butterfly_footer_beautify')
    parent_div_git.insertAdjacentHTML("beforeend",item_html)
    }
  var elist = 'null'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_footer_beautify_injector_config();
  }
  else if (epage === cpage){
    butterfly_footer_beautify_injector_config();
  }
  </script><!-- hexo injector body_end end --></body></html>